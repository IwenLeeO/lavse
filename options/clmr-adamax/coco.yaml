__include__: 'clmr.yaml'
exp:
  outpath: logs/coco_precomp.en/clmr-adamax/
dataset:
  train:
    data: coco_precomp.en
    workers: 0
  val: 
    data: [coco_precomp.en]
    workers: 0
  adapt:
    data: []
optimizer:
  name: adamax
  params:
    lr: 0.001
    gradual_warmup_steps: [0.5, 2.0, 8000] #torch.linspace
    lr_decay_epochs: [16000, 80000, 10000] #range 
    lr_decay_rate: .25
  lr_scheduler: 
    name: null  
  grad_clip: 2.
