__include__: 'clmr.yaml'
exp:
  outpath: logs/en-jt-de/clmr-adamax/
dataset:
  train:
    data: jap_precomp.en
    workers: 1
  val: 
    data: [jap_precomp.en, jap_precomp.jt, m30k_precomp.de]
    workers: 1
  adapt: 
    data: [jap_precomp.en-jt, m30k_precomp.en-de]
    workers: 1
optimizer:
  import: lavse.optimizers.factory
  name: adamax
  params:
    lr: 0.001 # 7e-4
    gradual_warmup_steps: [0.5, 2.0, 4000] #torch.linspace
    lr_decay_epochs: [10000, 20000, 2000] #range
    lr_decay_rate: .25
  lr_scheduler: 
    name: null
    params:
      step_size: 1000
      gamma: 1      
  grad_clip: 2.
