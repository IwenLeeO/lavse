{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonatas/.conda/envs/jonatas/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from vocab import Vocabulary, deserialize_vocab  # NOQA\n",
    "import evaluation\n",
    "import data\n",
    "import torch\n",
    "from train import validate\n",
    "from model import SCAN\n",
    "from data import get_loaders\n",
    "from tqdm import tqdm\n",
    "import numpy \n",
    "import json \n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from model import l2norm\n",
    "from evaluation import encode_data_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../temp/results_alpha/en/f30k/pc_gru_1/model_best.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderImagePrecomp(\n",
      "  (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
      ")\n",
      "()\n",
      "PartialGRU(\n",
      "  (embed): PartialConcat(\n",
      "    (embedding): EmbeddingLayer(\n",
      "      (embedding): Embedding(128, 24)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(624, 128, kernel_size=(1,), stride=(1,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(256, 300, kernel_size=(1,), stride=(1,))\n",
      "        (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rnn): GRU(300, 1024, batch_first=True, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load model and options\n",
    "checkpoint = torch.load(model_path)\n",
    "opt = checkpoint['opt']\n",
    "model = SCAN(opt)\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = deserialize_vocab(os.path.join('../',opt.vocab_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/datasets/flickr/dataset_flickr30k.json', 'r') as fp:\n",
    "    flickr = json.load(fp)\n",
    "    f30k = {x['filename']: x for x in flickr['images']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset')\n",
    "loader_en, loader_de = get_loaders(\n",
    "    splits=['test', 'test'], \n",
    "    langs=['en', 'de'],\n",
    "    data_name=opt.data_name, \n",
    "    vocab=vocab,\n",
    "    batch_size=opt.batch_size, \n",
    "    workers=opt.workers, opt=opt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = glob('/opt/datasets/flickr_features/pickles/*.pkl')\n",
    "features = {fname.split('/')[-1][:-3]: fname for fname in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-671530dd4675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "loader_en.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "loader_en.dataset.captions[1]\n",
    "print(len(loader_en.dataset.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(loader, idx):\n",
    "    instance = loader.dataset[idx]\n",
    "    instance = data.collate_fn_partial_inst(instance)\n",
    "    img_id = loader.dataset.ids[idx]\n",
    "    inst_dict = flickr['images'][img_id]\n",
    "    doug_features = np.load(features[inst_dict['filename'][:-3]])\n",
    "    return instance, inst_dict, doug_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance, f30k_info, doug_features = get_instance(loader_en, 1)\n",
    "images, captions, lengths, ids = instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'filename': u'1007129816.jpg',\n",
       "  u'imgid': 25,\n",
       "  u'sentences': [{u'imgid': 25,\n",
       "    u'raw': u'The man with pierced ears is wearing glasses and an orange hat.',\n",
       "    u'sentid': 125,\n",
       "    u'tokens': [u'the',\n",
       "     u'man',\n",
       "     u'with',\n",
       "     u'pierced',\n",
       "     u'ears',\n",
       "     u'is',\n",
       "     u'wearing',\n",
       "     u'glasses',\n",
       "     u'and',\n",
       "     u'an',\n",
       "     u'orange',\n",
       "     u'hat']},\n",
       "   {u'imgid': 25,\n",
       "    u'raw': u'A man with glasses is wearing a beer can crocheted hat.',\n",
       "    u'sentid': 126,\n",
       "    u'tokens': [u'a',\n",
       "     u'man',\n",
       "     u'with',\n",
       "     u'glasses',\n",
       "     u'is',\n",
       "     u'wearing',\n",
       "     u'a',\n",
       "     u'beer',\n",
       "     u'can',\n",
       "     u'crocheted',\n",
       "     u'hat']},\n",
       "   {u'imgid': 25,\n",
       "    u'raw': u'A man with gauges and glasses is wearing a Blitz hat.',\n",
       "    u'sentid': 127,\n",
       "    u'tokens': [u'a',\n",
       "     u'man',\n",
       "     u'with',\n",
       "     u'gauges',\n",
       "     u'and',\n",
       "     u'glasses',\n",
       "     u'is',\n",
       "     u'wearing',\n",
       "     u'a',\n",
       "     u'blitz',\n",
       "     u'hat']},\n",
       "   {u'imgid': 25,\n",
       "    u'raw': u'A man in an orange hat starring at something.',\n",
       "    u'sentid': 128,\n",
       "    u'tokens': [u'a',\n",
       "     u'man',\n",
       "     u'in',\n",
       "     u'an',\n",
       "     u'orange',\n",
       "     u'hat',\n",
       "     u'starring',\n",
       "     u'at',\n",
       "     u'something']},\n",
       "   {u'imgid': 25,\n",
       "    u'raw': u'A man wears an orange hat and glasses.',\n",
       "    u'sentid': 129,\n",
       "    u'tokens': [u'a',\n",
       "     u'man',\n",
       "     u'wears',\n",
       "     u'an',\n",
       "     u'orange',\n",
       "     u'hat',\n",
       "     u'and',\n",
       "     u'glasses']}],\n",
       "  u'sentids': [125, 126, 127, 128, 129],\n",
       "  u'split': u'test'},\n",
       " {'boxes': array([[ 68.75276 ,  99.88187 , 498.80203 , 460.078   ],\n",
       "         [ 84.464554,  14.729716, 393.6614  , 218.57661 ],\n",
       "         [183.36916 , 191.34756 , 229.59814 , 238.6488  ],\n",
       "         [250.7216  , 134.21994 , 384.5628  , 287.73425 ],\n",
       "         [234.45778 , 146.88919 , 402.87845 , 228.12326 ],\n",
       "         [318.77078 , 189.28322 , 370.39047 , 236.87523 ],\n",
       "         [195.26874 , 239.63522 , 317.41794 , 352.3384  ],\n",
       "         [199.39159 ,  57.30107 , 370.568   , 367.07166 ],\n",
       "         [  0.      , 242.86305 , 130.58968 , 449.52325 ],\n",
       "         [357.4665  , 266.87845 , 498.80203 , 460.078   ],\n",
       "         [189.64507 ,  94.22221 , 390.25745 , 184.53561 ],\n",
       "         [101.15886 , 279.64557 , 350.6915  , 460.078   ],\n",
       "         [428.96906 , 299.8381  , 479.95093 , 368.47067 ],\n",
       "         [239.86717 , 221.48836 , 381.4745  , 314.88937 ],\n",
       "         [ 23.098862, 236.57475 , 153.37347 , 361.7251  ],\n",
       "         [305.35095 , 234.21194 , 363.2544  , 277.3931  ],\n",
       "         [214.96469 , 210.38925 , 362.3695  , 321.57983 ],\n",
       "         [  0.      ,   0.      , 498.80203 , 322.73917 ],\n",
       "         [372.892   , 332.62347 , 494.008   , 455.40158 ],\n",
       "         [430.091   , 295.949   , 490.36743 , 340.5374  ],\n",
       "         [300.09723 , 178.387   , 337.64066 , 213.12921 ],\n",
       "         [187.3081  ,  69.567314, 253.86244 , 118.821655],\n",
       "         [308.2448  , 324.9151  , 476.0461  , 455.902   ],\n",
       "         [211.29008 , 203.55621 , 243.74704 , 240.02327 ],\n",
       "         [  0.      ,   0.      , 498.80203 , 220.90933 ],\n",
       "         [163.26811 , 117.03524 , 371.37253 , 211.93292 ],\n",
       "         [244.10336 , 165.6801  , 363.56635 , 206.35226 ],\n",
       "         [176.27971 , 141.26125 , 342.8001  , 383.87433 ],\n",
       "         [192.83484 ,  79.23602 , 245.1125  , 127.359924],\n",
       "         [ 42.37931 , 254.96202 , 140.72821 , 407.78943 ],\n",
       "         [277.18698 , 261.12115 , 360.2128  , 308.72177 ],\n",
       "         [213.76286 ,  77.87939 , 241.67647 , 107.86326 ],\n",
       "         [  0.      , 280.791   , 498.80203 , 460.078   ],\n",
       "         [156.3034  , 107.717834, 467.5809  , 301.04858 ],\n",
       "         [  0.      , 211.74045 , 180.70598 , 427.86124 ],\n",
       "         [293.0846  , 263.8864  , 366.903   , 304.4835  ]], dtype=float32),\n",
       "  'features': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.9096650e-01,\n",
       "          2.4525802e-01, 2.8361076e-02],\n",
       "         [0.0000000e+00, 0.0000000e+00, 7.1382606e-03, ..., 1.1683115e-01,\n",
       "          8.0459589e-01, 1.4194021e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 3.1631827e-01, ..., 0.0000000e+00,\n",
       "          4.4968834e+00, 4.4815196e-03],\n",
       "         ...,\n",
       "         [0.0000000e+00, 0.0000000e+00, 2.9416103e-02, ..., 3.0685720e-01,\n",
       "          1.4311926e+00, 1.2546119e-01],\n",
       "         [1.0534195e-01, 1.0505779e-01, 1.4848264e-02, ..., 0.0000000e+00,\n",
       "          5.2386618e+00, 8.0250925e-01],\n",
       "         [0.0000000e+00, 1.3599391e-03, 7.9632951e-03, ..., 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00]], dtype=float32),\n",
       "  'image_h': 461,\n",
       "  'image_id': '1007129816.jpg',\n",
       "  'image_w': 500,\n",
       "  'num_boxes': 36})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f30k_info,doug_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 36, 1024]), torch.Size([1, 14, 1024]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_enc, text_enc, lens = model.forward_emb(images, captions, lengths=lengths)\n",
    "img_enc = l2norm(img_enc, 2)\n",
    "text_enc = l2norm(text_enc, 2)\n",
    "img_enc.shape, text_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = img_enc.bmm(text_enc.permute(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 36, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonatas",
   "language": "python",
   "name": "jonatas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
